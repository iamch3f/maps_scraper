# Google Maps Scraper API v2.0 - OPTIMIZED

High-performance Google Maps scraper with 5 key optimizations for VPS deployment.

## üöÄ Performance Improvements

| Optimization | Description | Impact |
|--------------|-------------|--------|
| Request Interception | Blocks images, fonts, CSS | 3-5x faster |
| Parallel Workers | Multiple browser contexts | 3x faster |
| Browser Pool | Reuses browser instances | No cold start |
| Smart Waits | Dynamic timeouts | 2x faster |
| Batch URLs | Collect then scrape | Less clicking |

**Result:** ~0.3-0.5 sec/listing (vs ~4 sec before)

## üì¶ Quick Start

### Local Testing

```bash
npm install
npm start
```

### Docker

```bash
docker-compose up --build
```

## ‚òÅÔ∏è Coolify Deployment

### 1. Create Application

1. Coolify Dashboard ‚Üí **New Resource**
2. Select **Application**
3. Choose **Dockerfile** build

### 2. Connect Repository

Option A: **Git Repo**
- Connect your GitHub/GitLab repo

Option B: **Manual Deploy**
- Upload files via Coolify UI

### 3. Configure Settings

| Setting | Value |
|---------|-------|
| Port | 3000 |
| Health Check | `/health` |
| Build | Dockerfile |

### 4. Environment Variables

```env
PORT=3000
WORKERS=3
MAX_CONCURRENT_JOBS=5
API_KEY=your-secret-key  # optional
```

### 5. Resource Limits (Recommended)

| Resource | Value |
|----------|-------|
| CPU | 2 cores |
| Memory | 4 GB |
| Shared Memory | 2 GB |

### 6. Deploy

Click **Deploy** and wait for build to complete.

## üì° API Usage

### Single Scrape

```bash
curl -X POST https://your-domain.com/scrape \
  -H "Content-Type: application/json" \
  -H "X-API-KEY: your-key" \
  -d '{"query": "istanbul kuaf√∂r", "maxResults": 20, "workers": 3}'
```

### Bulk Scrape

```bash
curl -X POST https://your-domain.com/scrape/bulk \
  -H "Content-Type: application/json" \
  -d '{"queries": ["query1", "query2"], "maxResults": 10}'
```

### Async Job

```bash
# Start job
curl -X POST https://your-domain.com/scrape/async \
  -d '{"query": "test"}'

# Check status
curl https://your-domain.com/scrape/status/{jobId}
```

## üîß n8n Integration

```
HTTP Request Node:
  Method: POST
  URL: http://scraper-container:3000/scrape
  Body: {"query": "...", "maxResults": 20}
```

## ‚öôÔ∏è Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| PORT | 3000 | Server port |
| WORKERS | 3 | Parallel contexts |
| MAX_CONCURRENT_JOBS | 5 | Rate limit |
| API_KEY | - | Auth key (optional) |
| PROXY_URL | - | Proxy server (optional) |

## üõ°Ô∏è Security Notes

- Container runs as non-root user
- API key authentication supported
- Rate limiting prevents abuse

## üìä Expected Performance

| VPS Spec | Results/min |
|----------|-------------|
| 2 vCPU / 4GB | ~120 |
| 4 vCPU / 8GB | ~200 |
| 8 vCPU / 16GB | ~350 |
